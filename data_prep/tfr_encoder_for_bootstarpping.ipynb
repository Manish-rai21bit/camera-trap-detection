{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TFRecord encoder for bootstrap\n",
    "\n",
    "Code build for creating TFRecords from the Bootstrapped data. TFRecord in the format fit for model training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile tfr_encoder_for_bootstarpping.py\n",
    "\"\"\"Set of functions for creating TFRecord files with box leval annotations.\n",
    "Contains TFRecord encoder and decored and supporting functions for dealing\n",
    "with TFRecord.\"\"\"\n",
    "\n",
    "import tensorflow as tf\n",
    "import os, csv\n",
    "\n",
    "from data.utils import dataset_util\n",
    "# import data_prep.data_prep_utils as dataprep_utils\n",
    "# import data_prep.image as img\n",
    "\n",
    "\n",
    "\"\"\"This function takes the GSSS bounding box dataset published by in the paper\n",
    "    and converts it into a dictionary object. The column names in the CSV has to maintained.\n",
    "    \n",
    "1. csvtodict - creates dictionary objects. have to rename this function.\n",
    "2. dicttojson - JSON dump of the dictionary.\n",
    "3. jsontodict - JSON file to a dictionary for reading into a TFRecord.\n",
    "4. create_tf_example - Creates a tf_example.\n",
    "5. encode_to_tfr_record - Creates a TF Record file\"\"\"\n",
    "def csvtodict(Project_filepath, bb_data):\n",
    "    lst = []\n",
    "    record_dict = {}\n",
    "    csvfile = open(os.path.join(Project_filepath, bb_data), 'r')\n",
    "    csvdata = csv.reader(csvfile, delimiter=',')\n",
    "    first_row = next(csvdata)\n",
    "    for row in csvdata:\n",
    "        if row[0] not in record_dict: # the condition in lst2 is to pick only the images usd by schneider\n",
    "            record_dict[row[0]] = {'metadata' : {\"SiteID\": row[0].split('/')[1],\n",
    "                                  \"DateTime\": \"placeholder\", \n",
    "                                  \"Season\": row[0].split('/')[0]},\n",
    "                                    'images' : [{\"Path\" : os.path.join(Project_filepath, row[0] + '.JPG'), #points to the route of image on the disk\n",
    "                                \"URL\" : 'placeholder',\n",
    "                                \"dim_x\" : 'placeholder',\n",
    "                                \"dim_y\" : 'placeholder',\n",
    "                                \"image_label\" : \"tbd\", # This is the primary label in case we want to have some for the whole image\n",
    "                                'observations' : []\n",
    "                               }]\n",
    "                                    }\n",
    "        record_dict[row[0]]['images'][0]['observations'].append({'bb_ymin': row[3], \n",
    "                                                   'bb_ymax': row[5], \n",
    "                                                      'bb_primary_label': row[1], \n",
    "                                                      'bb_xmin': row[2], \n",
    "                                                      'bb_xmax': row[4], \n",
    "                                                      'bb_label': {\"species\" : row[1],\n",
    "                                                    \"pose\" : \"standing/ sitting/ running\"\n",
    "                                                }})\n",
    "    return record_dict\n",
    "\n",
    "\n",
    "\"\"\" This function creates a tfrecord example from the dictionary element!\"\"\"\n",
    "def create_tf_example(data_dict, \n",
    "                      label_map\n",
    "                     ):\n",
    "#     encoded_jpg = img.resize_jpeg((data_dict['images'][0]['Path']),  1000)\n",
    "#     encoded_jpg_io = io.BytesIO(encoded_jpg)\n",
    "#     image = Image.open(encoded_jpg_io)\n",
    "#     width, height = image.size\n",
    "#     width = int(width)\n",
    "#     height = int(height)\n",
    "\n",
    "    filename = data_dict['images'][0]['Path'].encode('utf-8')\n",
    "    image_format = b'jpg'\n",
    "    xmins, xmaxs, ymins, ymaxs = [], [], [], []\n",
    "    classes_text, classes = [], []\n",
    "\n",
    "    for bb_record in data_dict['images'][0]['observations']:\n",
    "        xmins.append(float(bb_record['bb_xmin']))\n",
    "        xmaxs.append(float(bb_record['bb_xmax']))\n",
    "        ymins.append(float(bb_record['bb_ymin']))\n",
    "        ymaxs.append(float(bb_record['bb_ymax']))\n",
    "        classes_text.append(bb_record['bb_primary_label'].encode('utf8'))\n",
    "        classes.append(label_map[bb_record['bb_primary_label']])\n",
    "\n",
    "    tf_example = tf.train.Example(features=tf.train.Features(feature={\n",
    "#         'image/height': dataset_util.int64_feature(height),\n",
    "#         'image/width': dataset_util.int64_feature(width),\n",
    "#         'image/filename': dataset_util.bytes_feature(filename),\n",
    "#         'image/source_id': dataset_util.bytes_feature(filename),\n",
    "#         'image/encoded': dataset_util.bytes_feature(encoded_jpg),\n",
    "#         'image/format': dataset_util.bytes_feature(image_format),\n",
    "        'image/object/bbox/xmin': dataset_util.float_list_feature(xmins),\n",
    "        'image/object/bbox/xmax': dataset_util.float_list_feature(xmaxs),\n",
    "        'image/object/bbox/ymin': dataset_util.float_list_feature(ymins),\n",
    "        'image/object/bbox/ymax': dataset_util.float_list_feature(ymaxs),\n",
    "        'image/object/class/text': dataset_util.bytes_list_feature(classes_text),\n",
    "        'image/object/class/label': dataset_util.int64_list_feature(classes),\n",
    "    }))\n",
    "\n",
    "    \n",
    "    return tf_example\n",
    "\n",
    "\"\"\"This iterates over each dictionary item, creates tf examples, \n",
    "    serializes the tfrecord examples and writes to a tfrecord file!!!\n",
    "    As of now, it saves the TFRecord file in the home directory where the code is executed\"\"\"\n",
    "def encode_to_tfr_record(bounding_box_dict, label_map, out_tfr_file):\n",
    "    with tf.python_io.TFRecordWriter(out_tfr_file) as writer:\n",
    "        count = 0\n",
    "        for k, v in bounding_box_dict.items():\n",
    "            count+=1\n",
    "            if count%500==0:\n",
    "                print(\"processing event number %s : %s\" % (count, k))\n",
    "            example = create_tf_example(v, label_map)\n",
    "            writer.write(example.SerializeToString())\n",
    "            \n",
    "# add function for decoding tfrecords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Building the main file for running the encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile ../tfr_encoder_for_bootstarpping_main.py\n",
    "\"\"\"tfrecord encoder for the training dataset created in the bootstrapped step.\n",
    "\n",
    "python tfr_encoder_for_bootstarpping_main.py \\\n",
    "--Project_filepath '/home/ubuntu/data/tensorflow/my_workspace/training_demo/Predictions/' \\\n",
    "--bounding_box_csv 'snapshot_serengeti_test3.csv' \\\n",
    "--label_map_json '/home/ubuntu/data/tensorflow/my_workspace/camera-trap-detection/data/LILA/label_map.json' \\\n",
    "--output_tfrecord_file 'out_tfr_file.record'\n",
    "\"\"\"\n",
    "\n",
    "import argparse \n",
    "\n",
    "import data_prep.data_prep_utils as dataprep_utils\n",
    "import data_prep.tfr_encoder_for_bootstarpping as tfr\n",
    "\n",
    "if __name__=='__main__':\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument(\n",
    "    \"--Project_filepath\", type=str, required=True,\n",
    "    help=\"path to the image file\")\n",
    "    parser.add_argument(\n",
    "    \"--bounding_box_csv\", type=str, required=True,\n",
    "    help=\"csv with bounding boxes\")\n",
    "    parser.add_argument(\n",
    "    \"--label_map_json\", type=str, required=True,\n",
    "    help=\"label map json\")\n",
    "    parser.add_argument(\n",
    "    \"--output_tfrecord_file\", type=str, required=True,\n",
    "    help=\"output path for TFRecord\")\n",
    "    \n",
    "    args = parser.parse_args()\n",
    "\n",
    "    bounding_box_dict = tfr.csvtodict(args.Project_filepath, args.bounding_box_csv)\n",
    "    label_map = dataprep_utils.get_label_map_from_json(args.label_map_json)\n",
    "    tfr.encode_to_tfr_record(bounding_box_dict, label_map, args.output_tfrecord_file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
