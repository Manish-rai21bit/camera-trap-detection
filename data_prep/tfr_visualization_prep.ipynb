{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building ground for the visualization API.\n",
    "**Will include the Visualization for the following:**\n",
    "1. Raw images TF Records\n",
    "2. Predictions TF Records\n",
    "3. Training TF Records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting /home/ubuntu/data/tensorflow/my_workspace/camera-trap-detection/data_prep/tfr_visualization.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile /home/ubuntu/data/tensorflow/my_workspace/camera-trap-detection/data_prep/tfr_visualization.py\n",
    "\n",
    "\"\"\"Visualization API for:\n",
    "1. Raw images from the MSI. These images have been encoded to TF Record\n",
    "2. Predictions made by the infer_detection.py using the model\n",
    "3. Training TFRecords that has been encoded by TF Record\n",
    "\"\"\"\n",
    "\n",
    "import tensorflow as tf\n",
    "import os, csv, io, sys\n",
    "from PIL import Image\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "from matplotlib import pyplot as plt\n",
    "matplotlib.use('Agg')\n",
    "\n",
    "tf.enable_eager_execution()\n",
    "\n",
    "sys.path.append('/home/ubuntu/data/tensorflow/my_workspace/camera-trap-detection/')\n",
    "\n",
    "from data.utils import dataset_util\n",
    "\n",
    "\n",
    "# Decoding the raw images\n",
    "def decode_record_raw_image(serialized_example):\n",
    "    \"\"\"Decode record for the raw images.\"\"\"\n",
    "    context_features = {\n",
    "                        'image/filename': tf.FixedLenFeature([], tf.string),\n",
    "                        'image/encoded': tf.FixedLenFeature([], tf.string),\n",
    "                        'image/format': tf.FixedLenFeature([], tf.string)\n",
    "                    }\n",
    "\n",
    "\n",
    "    context, sequence = tf.parse_single_sequence_example(serialized=serialized_example,\n",
    "                                              context_features=context_features,\n",
    "#                                               sequence_features=sequence_features,\n",
    "                                              example_name=None,\n",
    "                                              name=None)\n",
    "\n",
    "    return ({k: v for k, v in context.items()},{k: v for k, v in sequence.items()})\n",
    "\n",
    "# Decoding Detection TFRecord\n",
    "def decode_record_pred(serialized_example):\n",
    "    \"\"\"Decode the TFRecord data for each example from the detections. \"\"\"\n",
    "    context_features = {\n",
    "                        'image/filename': tf.FixedLenFeature([], tf.string),\n",
    "                        'image/encoded': tf.FixedLenFeature([], tf.string),\n",
    "                        'image/format': tf.FixedLenFeature([], tf.string),\n",
    "                        \"image/detection/bbox/xmin\" : tf.VarLenFeature(tf.float32),\n",
    "                        \"image/detection/bbox/xmax\" : tf.VarLenFeature(tf.float32),\n",
    "                        \"image/detection/bbox/ymin\" : tf.VarLenFeature(tf.float32),\n",
    "                        \"image/detection/bbox/ymax\" : tf.VarLenFeature(tf.float32),\n",
    "                        \"image/detection/label\" : tf.VarLenFeature(tf.int64),\n",
    "                        \"image/detection/score\" : tf.VarLenFeature(tf.float32)\n",
    "                    }\n",
    "\n",
    "\n",
    "    context, sequence = tf.parse_single_sequence_example(serialized=serialized_example,\n",
    "                                              context_features=context_features,\n",
    "#                                               sequence_features=sequence_features,\n",
    "                                              example_name=None,\n",
    "                                              name=None)\n",
    "\n",
    "    return ({k: v for k, v in context.items()},{k: v for k, v in sequence.items()})\n",
    "\n",
    "# Decoding Training TFRecord\n",
    "def decode_record_training_image(serialized_example):\n",
    "    \"\"\"Decode the TFRecord data for each example from the training TFRecord. \"\"\"\n",
    "    context_features = {\n",
    "                        'image/height': tf.FixedLenFeature([], tf.int64),\n",
    "                        'image/width': tf.FixedLenFeature([], tf.int64),\n",
    "                        'image/filename': tf.FixedLenFeature([], tf.string),\n",
    "                        'image/source_id': tf.FixedLenFeature([], tf.string),\n",
    "                        'image/encoded': tf.FixedLenFeature([], tf.string),\n",
    "                        'image/format': tf.FixedLenFeature([], tf.string),\n",
    "                        \"image/object/bbox/xmin\" : tf.VarLenFeature(tf.float32),\n",
    "                        \"image/object/bbox/xmax\" : tf.VarLenFeature(tf.float32),\n",
    "                        \"image/object/bbox/ymin\" : tf.VarLenFeature(tf.float32),\n",
    "                        \"image/object/bbox/ymax\" : tf.VarLenFeature(tf.float32),\n",
    "                        \"image/object/class/text\" : tf.VarLenFeature(tf.string),\n",
    "                        \"image/object/class/label\" : tf.VarLenFeature(tf.int64)\n",
    "                    }\n",
    "\n",
    "\n",
    "    context, sequence = tf.parse_single_sequence_example(serialized=serialized_example,\n",
    "                                              context_features=context_features,\n",
    "#                                               sequence_features=sequence_features,\n",
    "                                              example_name=None,\n",
    "                                              name=None)\n",
    "\n",
    "    return ({k: v for k, v in context.items()},{k: v for k, v in sequence.items()})\n",
    "\n",
    "\n",
    "# Plot the raw images\n",
    "def plot_images_raw(filename_list, \n",
    "                    outfile, \n",
    "                    num_batches=1, \n",
    "                    batch_size= 2):\n",
    "    \"\"\"Plot n raw images and save it in the location given.\n",
    "    filename_list : list of TFRecords\n",
    "    \"\"\"\n",
    "\n",
    "    # Create a tensorflow dataset\n",
    "    dataset = tf.data.Dataset.from_tensor_slices(filename_list)\n",
    "    dataset = tf.data.TFRecordDataset(dataset)\n",
    "    dataset = dataset.shuffle(buffer_size=batch_size)\n",
    "    dataset = dataset.map(lambda x: decode_record_raw_image(serialized_example=x)).batch(batch_size)\n",
    "\n",
    "    for i, (context, sequence) in enumerate(dataset):\n",
    "        if i<num_batches:\n",
    "            for j in range(batch_size):\n",
    "                img = context['image/encoded'][j]\n",
    "                encoded_jpg_io = io.BytesIO(img.numpy())\n",
    "                image = Image.open(encoded_jpg_io)\n",
    "                width, height = image.size\n",
    "                # Create figure and axes\n",
    "                fig,ax = plt.subplots(1)\n",
    "                fig.set_size_inches(10, 8)\n",
    "                # Display the image\n",
    "                ax.set_title(context['image/filename'][j].numpy().decode('utf-8')+str(image.size))\n",
    "                ax.imshow(image)\n",
    "                fig.savefig(os.path.join(outfile, context['image/filename'][j].numpy().decode('utf-8').split('/')[-1]))\n",
    "                plt.clf\n",
    "\n",
    "\n",
    "# Plot the boxes for Detection TFRecord\n",
    "def plot_images_with_bbox_pred(filename_list, \n",
    "                               outfile, \n",
    "                               inv_label_map, \n",
    "                               num_batches=1, \n",
    "                               score_threshold=0.5, \n",
    "                               batch_size= 2):\n",
    "    \"\"\"Plot n images with bounding boxes and save it in the location givenself.\n",
    "    filename_list : list of TFRecords\n",
    "    \"\"\"\n",
    "\n",
    "    # Create a tensorflow dataset\n",
    "    dataset = tf.data.Dataset.from_tensor_slices(filename_list)\n",
    "    dataset = tf.data.TFRecordDataset(dataset)\n",
    "    dataset = dataset.shuffle(buffer_size=batch_size)\n",
    "    dataset = dataset.map(lambda x: decode_record_pred(serialized_example=x)).batch(batch_size)\n",
    "\n",
    "    for i, (context, sequence) in enumerate(dataset):\n",
    "        if i<num_batches:\n",
    "            batch_shape = context['image/detection/bbox/xmin'].dense_shape\n",
    "            filename = context['image/filename']\n",
    "            xmin_d = tf.sparse_tensor_to_dense(context['image/detection/bbox/xmin'])\n",
    "            ymin_d = tf.sparse_tensor_to_dense(context['image/detection/bbox/ymin'])\n",
    "            xmax_d = tf.sparse_tensor_to_dense(context['image/detection/bbox/xmax'])\n",
    "            ymax_d = tf.sparse_tensor_to_dense(context['image/detection/bbox/ymax'])\n",
    "            label_d = tf.sparse_tensor_to_dense(context['image/detection/label'])\n",
    "            score = tf.sparse_tensor_to_dense(context['image/detection/score'])\n",
    "\n",
    "            for rec_i in range(0, int(batch_shape[0])):\n",
    "                xmins_d, ymins_d, xmaxs_d, ymaxs_d, labels_d, scores, filenames = [], [], [], [], [], [], []\n",
    "                \n",
    "                img = context['image/encoded'][rec_i]\n",
    "                encoded_jpg_io = io.BytesIO(img.numpy())\n",
    "                image = Image.open(encoded_jpg_io)\n",
    "                width, height = image.size\n",
    "                \n",
    "                filenames.append(filename[rec_i].numpy().decode('utf-8'))\n",
    "                \n",
    "                for box_i in range(0, int(batch_shape[1])):                    \n",
    "                    if score[rec_i, box_i] >= score_threshold:\n",
    "#                         continue\n",
    "                        xmins_d.append((xmin_d[rec_i, box_i].numpy())*width)\n",
    "                        ymins_d.append((ymin_d[rec_i, box_i].numpy())*height)\n",
    "                        xmaxs_d.append((xmax_d[rec_i, box_i].numpy())*width)\n",
    "                        ymaxs_d.append((ymax_d[rec_i, box_i].numpy())*height)\n",
    "                        labels_d.append(int(label_d[rec_i, box_i].numpy()))\n",
    "                        scores.append(score[rec_i, box_i].numpy())\n",
    "\n",
    "                # Create figure and axes\n",
    "                fig,ax = plt.subplots(1)\n",
    "                fig.set_size_inches(10, 8)\n",
    "                # Display the image\n",
    "                ax.set_title(filename[rec_i].numpy().decode('utf-8'))\n",
    "                ax.imshow(image)\n",
    "                for s in range(len(xmins_d)):\n",
    "                    rect = patches.Rectangle((xmins_d[s],ymins_d[s]),(xmaxs_d[s]-xmins_d[s]), \\\n",
    "                                             (ymaxs_d[s] - ymins_d[s]),linewidth=2,edgecolor='b',facecolor='none')\n",
    "                    ax.add_patch(rect)\n",
    "\n",
    "                    rx, ry = rect.get_xy()\n",
    "                    cx = rx # + rect.get_width()/2.0\n",
    "                    cy = ry # + rect.get_height()/2.0\n",
    "\n",
    "                    ax.annotate((inv_label_map[labels_d[s]], str(scores[s])+str('%')), (cx, cy), color='b', weight='bold', \n",
    "                                fontsize=8, ha='left', va='top') \n",
    "                fig.savefig(os.path.join(outfile, filename[rec_i].numpy().decode('utf-8').split('/')[-1]))\n",
    "                plt.clf\n",
    "                \n",
    "# Plot the boxes for Training TFRecord\n",
    "def plot_images_training_with_bbox(filename_list, \n",
    "                                   outfile, \n",
    "                                   inv_label_map, \n",
    "                                   num_batches=1, \n",
    "                                   batch_size= 2):\n",
    "    \"\"\"Plot n raw images and save it in the location givenself.\n",
    "    filename_list : list of TFRecords\n",
    "    \"\"\"\n",
    "\n",
    "    # Create a tensorflow dataset\n",
    "    dataset = tf.data.Dataset.from_tensor_slices(filename_list)\n",
    "    dataset = tf.data.TFRecordDataset(dataset)\n",
    "    dataset = dataset.shuffle(buffer_size=batch_size)\n",
    "    dataset = dataset.map(lambda x: decode_record_training_image(serialized_example=x)).batch(batch_size)\n",
    "\n",
    "    for i, (context, sequence) in enumerate(dataset):\n",
    "        if i<num_batches:\n",
    "            batch_shape = context['image/object/bbox/xmin'].dense_shape\n",
    "            filename = context['image/filename']\n",
    "            xmin = tf.sparse_tensor_to_dense(context['image/object/bbox/xmin'])\n",
    "            ymin = tf.sparse_tensor_to_dense(context['image/object/bbox/ymin'])\n",
    "            xmax = tf.sparse_tensor_to_dense(context['image/object/bbox/xmax'])\n",
    "            ymax = tf.sparse_tensor_to_dense(context['image/object/bbox/ymax'])\n",
    "            label = tf.sparse_tensor_to_dense(context['image/object/class/label'])\n",
    "            \n",
    "            for rec_i in range(0, int(batch_shape[0])):\n",
    "                xmins, ymins, xmaxs, ymaxs, labels = [], [], [], [], []\n",
    "\n",
    "                img = context['image/encoded'][rec_i]\n",
    "                encoded_jpg_io = io.BytesIO(img.numpy())\n",
    "                image = Image.open(encoded_jpg_io)\n",
    "                width, height = image.size\n",
    "                \n",
    "                for box_i in range(0, int(batch_shape[1])):   \n",
    "                    xmins.append((xmin[rec_i, box_i].numpy())*width)\n",
    "                    ymins.append((ymin[rec_i, box_i].numpy())*height)\n",
    "                    xmaxs.append((xmax[rec_i, box_i].numpy())*width)\n",
    "                    ymaxs.append((ymax[rec_i, box_i].numpy())*height)\n",
    "                    labels.append(int(label[rec_i, box_i].numpy()))\n",
    "                    \n",
    "                # Create figure and axes\n",
    "                fig,ax = plt.subplots(1)\n",
    "                fig.set_size_inches(10, 8)\n",
    "                # Display the image\n",
    "                ax.set_title(filename[rec_i].numpy().decode('utf-8'))\n",
    "                ax.imshow(image)\n",
    "                for s in range(len(xmins)):\n",
    "                    if int(labels[s]) != 0:\n",
    "                        rect = patches.Rectangle((xmins[s],ymins[s]),(xmaxs[s]-xmins[s]), \\\n",
    "                                                 (ymaxs[s] - ymins[s]),linewidth=2,edgecolor='b',facecolor='none')\n",
    "                        ax.add_patch(rect)\n",
    "                        rx, ry = rect.get_xy()\n",
    "                        cx = rx # + rect.get_width()/2.0\n",
    "                        cy = ry # + rect.get_height()/2.0\n",
    "\n",
    "                        ax.annotate(inv_label_map[labels[s]], (cx, cy), color='b', weight='bold', \n",
    "                                fontsize=8, ha='left', va='top') \n",
    "                fig.savefig(os.path.join(outfile, filename[rec_i].numpy().decode('utf-8').split('/')[-1]))\n",
    "                plt.clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting /home/ubuntu/data/tensorflow/my_workspace/camera-trap-detection/tfr_visualization_main.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile /home/ubuntu/data/tensorflow/my_workspace/camera-trap-detection/tfr_visualization_main.py\n",
    "\"\"\"Main function for visualizing the predictions and saving \n",
    "them to a directory\n",
    "\n",
    "python tfr_visualization_main.py \\\n",
    "--filename_list '/home/ubuntu/data/tensorflow/my_workspace/training_demo/Predictions/snapshot_serengeti_s01_s06-0-10000.record' \\\n",
    "--outfile '/home/ubuntu/data/tensorflow/my_workspace/camera-trap-detection/test_images/' \\\n",
    "--label_map_json '/home/ubuntu/data/tensorflow/my_workspace/camera-trap-detection/data/LILA/label_map.json' \\\n",
    "--num_batches 256\n",
    "\"\"\"\n",
    "\n",
    "import json, argparse\n",
    "import matplotlib\n",
    "matplotlib.use('Agg')\n",
    "\n",
    "\n",
    "import data_prep.tfr_visualization as visual\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument(\n",
    "        \"--filename_list\", nargs='+', type=str, required=True,\n",
    "        help=\"Path to TFRecord files. In form of list\")\n",
    "    parser.add_argument(\n",
    "        \"--outfile\", type=str, required=True,\n",
    "        help=\"output directory of the image to be saved\"\n",
    "        )\n",
    "    parser.add_argument(\n",
    "        \"--label_map_json\", type=str, required=True,\n",
    "        help=\"label map json\"\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--num_batches\", type=int, default=1,\n",
    "        help=\"number of batches to save. batch size = 2\"\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--score_threshold\", type=float, default=0.5,\n",
    "        help=\"threshold of the detected box to be plotted\"\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--TFRecord_type\", type=str, required=True,\n",
    "        help=\"Type of the TF Record. \\\n",
    "             Pred: for TFRecord with Predictions, \\\n",
    "             Train: for TFRecord with Training dataset\"\n",
    "    )\n",
    "\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    with open(args.label_map_json, 'r') as f:\n",
    "         label_map = json.load(f)\n",
    "    inv_label_map = {v: k for k, v in label_map.items()}\n",
    "    \n",
    "    if args.TFRecord_type=='Pred':\n",
    "        visual.plot_images_with_bbox_pred(args.filename_list, \n",
    "                                          args.outfile, \n",
    "                                          inv_label_map, \n",
    "                                          args.num_batches, \n",
    "                                          score_threshold = args.score_threshold)\n",
    "    elif args.TFRecord_type=='Train':\n",
    "        visual.plot_images_training_with_bbox(args.filename_list, \n",
    "                                          args.outfile, \n",
    "                                          inv_label_map, \n",
    "                                          args.num_batches)\n",
    "    elif args.TFRecord_type=='Raw':\n",
    "        visual.plot_images_raw(args.filename_list, \n",
    "                               args.outfile,\n",
    "                              args.num_batches)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF Record parser\n",
    "Function to parse the TF Record and plot any image along with their boxes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import os, csv, io, sys\n",
    "from PIL import Image\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "from matplotlib import pyplot as plt\n",
    "matplotlib.use('Agg')\n",
    "\n",
    "tf.enable_eager_execution()\n",
    "\n",
    "sys.path.append('/home/ubuntu/data/tensorflow/my_workspace/camera-trap-detection/')\n",
    "\n",
    "from data.utils import dataset_util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'tensorflow.core.example.feature_pb2.Feature'>\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "# Some manual and visual checks on the tfrecord data\n",
    "c = 0\n",
    "tfrecords_filename = '/home/ubuntu/data/tensorflow/my_workspace/camera-trap-detection/data/test_snapshot_serengeti_s10/encoded_images_for_test/msi_test_image_list_s10.record-00000-of-00100'\n",
    "record_iterator = tf.python_io.tf_record_iterator(path=tfrecords_filename)\n",
    "\n",
    "for s_example in record_iterator:\n",
    "    example = tf.train.Example()\n",
    "    example.ParseFromString(s_example)\n",
    "    \n",
    "    box_labels = (example.features.feature[\"image/object/class/label\"]\n",
    "                                .int64_list)\n",
    "    box_class = (example.features.feature[\"image/object/class/text\"]\n",
    "                                .bytes_list)\n",
    "    example = tf.train.Example.FromString(s_example)\n",
    "    c +=1\n",
    "    if c == 1:\n",
    "        img = example.features.feature['image/encoded']\n",
    "        print(type(img))\n",
    "#         encoded_jpg_io = io.BytesIO(img.numpy())\n",
    "#         image = Image.open(encoded_jpg_io)\n",
    "#         width, height = image.size\n",
    "#         print(width)\n",
    "#         print(box_labels, box_class)\n",
    "#         print(example.features.feature['image/width'])\n",
    "    else :\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
