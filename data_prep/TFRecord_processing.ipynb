{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to process the TFRecord and create a csv with the fields - filename, class, xmin, ymin, xmax, ymax, prediction_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import modules\n",
    "import csv, os, sys, io\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "sys.path.append('/home/ubuntu/data/tensorflow/my_workspace/camera-trap-detection/data/')\n",
    "from utils import dataset_util\n",
    "from PIL import ImageFile\n",
    "from PIL import Image\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input parameters\n",
    "filename_list = ['/home/ubuntu/data/tensorflow/my_workspace/training_demo/Predictions/snapshot_serengeti_s01_s06-0-10000.record']\n",
    "batch_size = 10000\n",
    "score_threshold = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"This section contains the helper functions needed for \n",
    "decoding TFRecord...\n",
    "1. decode_record: This function decodes a TFexample with the following features\n",
    "               'image/filename' - a fixed length feature with the file name\n",
    "               'image/encoded' - a fixed length feature with image encodings\n",
    "               'image/format' - a fixed length features with image format\n",
    "               'image/detection/bbox/xmin' - a varaible name feature with normalized xmin values \n",
    "               'image/detection/bbox/xmax' - normalized xmax values\n",
    "               'image/detection/bbox/ymin' - normalized ymin values\n",
    "               'image/detection/bbox/ymax' - normalized ymax values\n",
    "               'image/detection/label' - bounding box labels\n",
    "               'image/detection/score' - prediction score\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "def decode_record(serialized_example):\n",
    "    context_features = {\n",
    "                        'image/filename': tf.FixedLenFeature([], tf.string),\n",
    "                        'image/encoded': tf.FixedLenFeature([], tf.string),\n",
    "                        'image/format': tf.FixedLenFeature([], tf.string),\n",
    "                        \"image/detection/bbox/xmin\" : tf.VarLenFeature(tf.float32),\n",
    "                        \"image/detection/bbox/xmax\" : tf.VarLenFeature(tf.float32),\n",
    "                        \"image/detection/bbox/ymin\" : tf.VarLenFeature(tf.float32),\n",
    "                        \"image/detection/bbox/ymax\" : tf.VarLenFeature(tf.float32),\n",
    "                        \"image/detection/label\" : tf.VarLenFeature(tf.int64),\n",
    "                        \"image/detection/score\" : tf.VarLenFeature(tf.float32)\n",
    "                    }\n",
    "\n",
    "\n",
    "    context, sequence = tf.parse_single_sequence_example(serialized=serialized_example,\n",
    "                                              context_features=context_features,\n",
    "#                                               sequence_features=sequence_features,\n",
    "                                              example_name=None,\n",
    "                                              name=None)\n",
    "\n",
    "    return ({k: v for k, v in context.items()},{k: v for k, v in sequence.items()})\n",
    "\n",
    "# Create an iterator to traverse the file\n",
    "dataset = tf.data.Dataset.from_tensor_slices(filename_list)\n",
    "dataset = tf.data.TFRecordDataset(dataset)\n",
    "dataset = dataset.map(lambda x: decode_record(serialized_example=x)).batch(batch_size)\n",
    "\n",
    "iterator = dataset.make_one_shot_iterator() # create the iterator\n",
    "batch_data = iterator.get_next()\n",
    "\n",
    "# Run the session and extract the feature values\n",
    "with tf.Session() as sess:\n",
    "    (context, sequence) = sess.run(batch_data)\n",
    "    img = context['image/encoded']\n",
    "    filename = context['image/filename']\n",
    "    # Features added during the detection phase \n",
    "    xmin_d = (context['image/detection/bbox/xmin'])\n",
    "    ymin_d = (context['image/detection/bbox/ymin'])\n",
    "    xmax_d = (context['image/detection/bbox/xmax'])\n",
    "    ymax_d = (context['image/detection/bbox/ymax'])\n",
    "    label_d = (context['image/detection/label'])\n",
    "    score = (context['image/detection/score'])\n",
    "    \n",
    "    file_name = [] # list of mages with no groundtruth\n",
    "    no_prediction = [] # Storing the image name of the correct predictions\n",
    "    incorrect_prediction = [] # Storing the image name of the incorrect predictions\n",
    "    \n",
    "    # index of the boxes with score greater than the threshold\n",
    "    index_score_gt_threshold = score[1] > score_threshold # can be checked only once. So moved out of the for loop\n",
    "    xmins_d, ymins_d, xmaxs_d, ymaxs_d, labels_d, scores = [], [], [], [], [], []\n",
    "    for rec_i in range(len(img)):\n",
    "        encoded_jpg_io = io.BytesIO(img[rec_i])\n",
    "        image = Image.open(encoded_jpg_io)\n",
    "        width, height = image.size\n",
    "        \n",
    "        # index of the image\n",
    "        index_image_rec_i = xmin_d[0][:, 0] == rec_i\n",
    "        # index of the boxes with score greater than the threshold\n",
    "        # index_score_gt_threshold = score[1] > score_threshold\n",
    "        index_img_gt_thres = list(np.where([a and b for a, b in zip(index_image_rec_i, index_score_gt_threshold)])[0])\n",
    "        \n",
    "        xmins_d = xmins_d + list(xmin_d[1][index_img_gt_thres])\n",
    "        ymins_d = ymins_d + list(ymin_d[1][index_img_gt_thres])\n",
    "        xmaxs_d = xmaxs_d + list(xmax_d[1][index_img_gt_thres])\n",
    "        ymaxs_d = ymaxs_d + list(ymax_d[1][index_img_gt_thres])\n",
    "        labels_d = labels_d + list(label_d[1][index_img_gt_thres])\n",
    "        scores = scores + list(score[1][index_img_gt_thres])\n",
    "        file_name = file_name + [filename[rec_i].decode('ascii')]*len(index_img_gt_thres)\n",
    "        \n",
    "        if len(index_img_gt_thres)==0:\n",
    "            no_prediction.append(filename[rec_i].decode('ascii'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Create pandas dataframe\n",
    "df_predictions = pd.DataFrame({'labels':labels_d, \n",
    "                               'filename':file_name,\n",
    "                               'score': scores,\n",
    "                               'xmin': xmins_d,\n",
    "                               'ymin': ymins_d,\n",
    "                               'xmax': xmaxs_d,\n",
    "                               'ymax': ymaxs_d})\n",
    "# write predictions to csv\n",
    "df_predictions.to_csv('/home/ubuntu/data/tensorflow/my_workspace/training_demo/Predictions/snapshot_serengeti_s01_s06-0-10000.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>labels</th>\n",
       "      <th>score</th>\n",
       "      <th>xmax</th>\n",
       "      <th>xmin</th>\n",
       "      <th>ymax</th>\n",
       "      <th>ymin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>S1/B04/B04_R1/S1_B04_R1_PICT0009</td>\n",
       "      <td>5</td>\n",
       "      <td>0.990571</td>\n",
       "      <td>0.790646</td>\n",
       "      <td>0.354476</td>\n",
       "      <td>0.946177</td>\n",
       "      <td>0.552227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>S1/B04/B04_R1/S1_B04_R1_PICT0012</td>\n",
       "      <td>5</td>\n",
       "      <td>0.992132</td>\n",
       "      <td>0.213541</td>\n",
       "      <td>0.073717</td>\n",
       "      <td>0.806135</td>\n",
       "      <td>0.643844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>S1/B04/B04_R1/S1_B04_R1_PICT0017</td>\n",
       "      <td>5</td>\n",
       "      <td>0.995016</td>\n",
       "      <td>0.303868</td>\n",
       "      <td>0.150443</td>\n",
       "      <td>0.842562</td>\n",
       "      <td>0.610818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>S1/B04/B04_R1/S1_B04_R1_PICT0018</td>\n",
       "      <td>5</td>\n",
       "      <td>0.996753</td>\n",
       "      <td>0.760716</td>\n",
       "      <td>0.496047</td>\n",
       "      <td>0.937487</td>\n",
       "      <td>0.676392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>S1/B05/B05_R1/S1_B05_R1_PICT0002</td>\n",
       "      <td>7</td>\n",
       "      <td>0.996732</td>\n",
       "      <td>0.825283</td>\n",
       "      <td>0.532042</td>\n",
       "      <td>0.930573</td>\n",
       "      <td>0.527430</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           filename  labels     score      xmax      xmin  \\\n",
       "0  S1/B04/B04_R1/S1_B04_R1_PICT0009       5  0.990571  0.790646  0.354476   \n",
       "1  S1/B04/B04_R1/S1_B04_R1_PICT0012       5  0.992132  0.213541  0.073717   \n",
       "2  S1/B04/B04_R1/S1_B04_R1_PICT0017       5  0.995016  0.303868  0.150443   \n",
       "3  S1/B04/B04_R1/S1_B04_R1_PICT0018       5  0.996753  0.760716  0.496047   \n",
       "4  S1/B05/B05_R1/S1_B05_R1_PICT0002       7  0.996732  0.825283  0.532042   \n",
       "\n",
       "       ymax      ymin  \n",
       "0  0.946177  0.552227  \n",
       "1  0.806135  0.643844  \n",
       "2  0.842562  0.610818  \n",
       "3  0.937487  0.676392  \n",
       "4  0.930573  0.527430  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_predictions.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
