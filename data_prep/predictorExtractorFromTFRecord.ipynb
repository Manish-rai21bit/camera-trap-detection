{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to process the TFRecord and create a csv with the fields - filename, class, xmin, ymin, xmax, ymax, prediction_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import modules\n",
    "import csv, os, sys, io\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "sys.path.append('/home/ubuntu/data/tensorflow/my_workspace/camera-trap-detection/data/')\n",
    "from utils import dataset_util\n",
    "from PIL import ImageFile\n",
    "from PIL import Image\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input parameters\n",
    "filename_list = ['/home/ubuntu/data/tensorflow/my_workspace/training_demo/Predictions/snapshot_serengeti_s01_s06-0-10000.record']\n",
    "batch_size = 2\n",
    "score_threshold = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"This section contains the helper functions needed for \n",
    "decoding TFRecord...\n",
    "1. decode_record: This function decodes a TFexample with the following features\n",
    "               'image/filename' - a fixed length feature with the file name\n",
    "               'image/encoded' - a fixed length feature with image encodings\n",
    "               'image/format' - a fixed length features with image format\n",
    "               'image/detection/bbox/xmin' - a varaible name feature with normalized xmin values \n",
    "               'image/detection/bbox/xmax' - normalized xmax values\n",
    "               'image/detection/bbox/ymin' - normalized ymin values\n",
    "               'image/detection/bbox/ymax' - normalized ymax values\n",
    "               'image/detection/label' - bounding box labels\n",
    "               'image/detection/score' - prediction score\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "def decode_record(serialized_example):\n",
    "    context_features = {\n",
    "                        'image/filename': tf.FixedLenFeature([], tf.string),\n",
    "                        'image/encoded': tf.FixedLenFeature([], tf.string),\n",
    "                        'image/format': tf.FixedLenFeature([], tf.string),\n",
    "                        \"image/detection/bbox/xmin\" : tf.VarLenFeature(tf.float32),\n",
    "                        \"image/detection/bbox/xmax\" : tf.VarLenFeature(tf.float32),\n",
    "                        \"image/detection/bbox/ymin\" : tf.VarLenFeature(tf.float32),\n",
    "                        \"image/detection/bbox/ymax\" : tf.VarLenFeature(tf.float32),\n",
    "                        \"image/detection/label\" : tf.VarLenFeature(tf.int64),\n",
    "                        \"image/detection/score\" : tf.VarLenFeature(tf.float32)\n",
    "                    }\n",
    "\n",
    "\n",
    "    context, sequence = tf.parse_single_sequence_example(serialized=serialized_example,\n",
    "                                              context_features=context_features,\n",
    "#                                               sequence_features=sequence_features,\n",
    "                                              example_name=None,\n",
    "                                              name=None)\n",
    "\n",
    "    return ({k: v for k, v in context.items()},{k: v for k, v in sequence.items()})\n",
    "\n",
    "# Create an iterator to traverse the file\n",
    "dataset = tf.data.Dataset.from_tensor_slices(filename_list)\n",
    "dataset = tf.data.TFRecordDataset(dataset)\n",
    "dataset = dataset.map(lambda x: decode_record(serialized_example=x)).batch(batch_size)\n",
    "\n",
    "iterator = dataset.make_one_shot_iterator() # create the iterator\n",
    "batch_data = iterator.get_next()\n",
    "\n",
    "# Run the session and extract the feature values\n",
    "with tf.Session() as sess:\n",
    "    (context, sequence) = sess.run(batch_data)\n",
    "    img = context['image/encoded']\n",
    "    filename = context['image/filename']\n",
    "    # Features added during the detection phase \n",
    "    xmin_d = (context['image/detection/bbox/xmin'])\n",
    "    ymin_d = (context['image/detection/bbox/ymin'])\n",
    "    xmax_d = (context['image/detection/bbox/xmax'])\n",
    "    ymax_d = (context['image/detection/bbox/ymax'])\n",
    "    label_d = (context['image/detection/label'])\n",
    "    score = (context['image/detection/score'])\n",
    "    \n",
    "    file_name = [] # list of mages with no groundtruth\n",
    "    no_prediction = [] # Storing the image name of the correct predictions\n",
    "    incorrect_prediction = [] # Storing the image name of the incorrect predictions\n",
    "    \n",
    "    # index of the boxes with score greater than the threshold\n",
    "    index_score_gt_threshold = score[1] > score_threshold # can be checked only once. So moved out of the for loop\n",
    "    xmins_d, ymins_d, xmaxs_d, ymaxs_d, labels_d, scores = [], [], [], [], [], []\n",
    "    for rec_i in range(len(img)):\n",
    "        encoded_jpg_io = io.BytesIO(img[rec_i])\n",
    "        image = Image.open(encoded_jpg_io)\n",
    "        width, height = image.size\n",
    "        \n",
    "        # index of the image\n",
    "        index_image_rec_i = xmin_d[0][:, 0] == rec_i\n",
    "        # index of the boxes with score greater than the threshold\n",
    "        # index_score_gt_threshold = score[1] > score_threshold\n",
    "        index_img_gt_thres = list(np.where([a and b for a, b in zip(index_image_rec_i, index_score_gt_threshold)])[0])\n",
    "        \n",
    "        xmins_d = xmins_d + list(xmin_d[1][index_img_gt_thres])\n",
    "        ymins_d = ymins_d + list(ymin_d[1][index_img_gt_thres])\n",
    "        xmaxs_d = xmaxs_d + list(xmax_d[1][index_img_gt_thres])\n",
    "        ymaxs_d = ymaxs_d + list(ymax_d[1][index_img_gt_thres])\n",
    "        labels_d = labels_d + list(label_d[1][index_img_gt_thres])\n",
    "        scores = scores + list(score[1][index_img_gt_thres])\n",
    "        file_name = file_name + [filename[rec_i].decode('ascii')]*len(index_img_gt_thres)\n",
    "        \n",
    "        if len(index_img_gt_thres)==0:\n",
    "            no_prediction.append(filename[rec_i].decode('ascii'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/test_env/lib/python3.5/site-packages/pandas/core/frame.py:6211: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  sort=sort)\n"
     ]
    }
   ],
   "source": [
    "# Create pandas dataframe\n",
    "df_predictions = pd.DataFrame({'labels':labels_d, \n",
    "                               'filename':file_name,\n",
    "                               'score': scores,\n",
    "                               'xmin': xmins_d,\n",
    "                               'ymin': ymins_d,\n",
    "                               'xmax': xmaxs_d,\n",
    "                               'ymax': ymaxs_d})\n",
    "df_predictions = df_predictions.append(pd.DataFrame({'filename':no_prediction}))\n",
    "# write predictions to csv\n",
    "# df_predictions.to_csv('/home/ubuntu/data/tensorflow/my_workspace/training_demo/Predictions/snapshot_serengeti_s01_s06-0-10000.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.35447586 0.35034874 0.35931507 0.38577777 0.32493898 0.34728947\n",
      "  0.30087775 0.34311253 0.32428855 0.338793   0.33718154 0.26118416\n",
      "  0.37068707 0.3337175  0.31924954 0.3565906  0.36697128 0.4031487\n",
      "  0.34903136 0.34533438 0.35516655 0.35425788 0.30074564 0.32234603\n",
      "  0.3591262  0.3749118  0.35370883 0.3342785  0.30659792 0.33644125\n",
      "  0.3722968  0.36111253 0.30157354 0.35065016 0.3808985  0.33131224\n",
      "  0.33277708 0.32537672 0.3539009  0.34703583 0.33562362 0.37821418\n",
      "  0.38263106 0.31913966 0.3315553  0.32440192 0.34541464 0.36812073\n",
      "  0.3518625  0.35086823 0.01591034 0.6654858  0.48245886 0.38707793\n",
      "  0.67438644 0.02038318 0.49792352 0.02922655 0.67533904 0.6854739\n",
      "  0.03442344 0.02255642 0.0064411  0.5011709  0.00749242 0.0295031\n",
      "  0.02598085 0.68445396 0.66680187 0.6707916  0.00942581 0.48725036\n",
      "  0.0217484  0.66822475 0.6602628 ]\n",
      " [0.07371732 0.06931121 0.09127627 0.0820457  0.06865181 0.07116377\n",
      "  0.08504913 0.07222109 0.075162   0.04551738 0.05854836 0.06489731\n",
      "  0.06899536 0.063446   0.07135492 0.07711749 0.06970225 0.07389247\n",
      "  0.07370544 0.0707923  0.07657881 0.07109559 0.05914025 0.07832681\n",
      "  0.08077488 0.07100267 0.07254846 0.06562728 0.07345091 0.06940449\n",
      "  0.07515284 0.07714723 0.07462526 0.06268227 0.06820167 0.07566806\n",
      "  0.09206755 0.06812085 0.07206768 0.07386455 0.07907818 0.7052043\n",
      "  0.07082161 0.082634   0.06206882 0.05999574 0.06721662 0.07718088\n",
      "  0.07516766 0.7349346  0.2502536  0.39599657 0.4928359  0.71432394\n",
      "  0.28979743 0.7260133  0.68176824 0.36215585 0.1564894  0.7325393\n",
      "  0.7061503  0.50494266 0.69983983 0.2464046  0.70196843 0.33418056\n",
      "  0.7094869  0.72843385 0.04209166 0.71847814 0.23859958 0.7223644\n",
      "  0.48170424 0.7116799  0.4095327 ]]\n",
      "0.34728947\n"
     ]
    }
   ],
   "source": [
    "# context['image/detection/bbox/ymin'][0].shape\n",
    "xmin_test = tf.sparse_tensor_to_dense(\n",
    "    context['image/detection/bbox/xmin'],\n",
    "    default_value=0,\n",
    "    validate_indices=True,\n",
    "    name=None\n",
    ")\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    print(sess.run(xmin_test))\n",
    "    print(sess.run(xmin_test[0,5]))\n",
    "# context['image/detection/bbox/xmin']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image: 0 finished\n",
      "image: 1 finished\n",
      "image: 2 finished\n",
      "image: 3 finished\n",
      "image: 4 finished\n",
      "image: 5 finished\n",
      "image: 6 finished\n",
      "image: 7 finished\n",
      "image: 8 finished\n",
      "image: 9 finished\n",
      "image: 10 finished\n",
      "image: 11 finished\n",
      "image: 12 finished\n",
      "image: 13 finished\n",
      "image: 14 finished\n",
      "image: 15 finished\n",
      "image: 16 finished\n",
      "image: 17 finished\n",
      "image: 18 finished\n",
      "image: 19 finished\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/test_env/lib/python3.5/site-packages/pandas/core/frame.py:6211: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  sort=sort)\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Predictor Extractor reads the TFRecords with predictions and outputs the csv file with the predictions \"\"\"\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "\n",
    "# tf.enable_eager_execution()\n",
    "\n",
    "def decode_record(serialized_example):\n",
    "    \"\"\"This section contains the helper functions needed for \n",
    "    decoding TFRecord...\n",
    "    1. decode_record: This function decodes a TFexample with the following features\n",
    "                   'image/filename' - a fixed length feature with the file name\n",
    "                   'image/encoded' - a fixed length feature with image encodings\n",
    "                   'image/format' - a fixed length features with image format\n",
    "                   'image/detection/bbox/xmin' - a varaible name feature with normalized xmin values \n",
    "                   'image/detection/bbox/xmax' - normalized xmax values\n",
    "                   'image/detection/bbox/ymin' - normalized ymin values\n",
    "                   'image/detection/bbox/ymax' - normalized ymax values\n",
    "                   'image/detection/label' - bounding box labels\n",
    "                   'image/detection/score' - prediction score\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    context_features = {\n",
    "                        'image/filename': tf.FixedLenFeature([], tf.string),\n",
    "                        'image/encoded': tf.FixedLenFeature([], tf.string),\n",
    "                        'image/format': tf.FixedLenFeature([], tf.string),\n",
    "                        \"image/detection/bbox/xmin\" : tf.VarLenFeature(tf.float32),\n",
    "                        \"image/detection/bbox/xmax\" : tf.VarLenFeature(tf.float32),\n",
    "                        \"image/detection/bbox/ymin\" : tf.VarLenFeature(tf.float32),\n",
    "                        \"image/detection/bbox/ymax\" : tf.VarLenFeature(tf.float32),\n",
    "                        \"image/detection/label\" : tf.VarLenFeature(tf.int64),\n",
    "                        \"image/detection/score\" : tf.VarLenFeature(tf.float32)\n",
    "                    }\n",
    "\n",
    "\n",
    "    context, sequence = tf.parse_single_sequence_example(serialized=serialized_example,\n",
    "                                              context_features=context_features,\n",
    "#                                               sequence_features=sequence_features,\n",
    "                                              example_name=None,\n",
    "                                              name=None)\n",
    "\n",
    "    return ({k: v for k, v in context.items()},{k: v for k, v in sequence.items()})\n",
    "\n",
    "\n",
    "tfrecord_path_list = ['/home/ubuntu/data/tensorflow/my_workspace/training_demo/Predictions/snapshot_serengeti_s01_s06-0-10000.record']\n",
    "batch_size = 512\n",
    "score_threshold = 0.5\n",
    "output_csv = '/home/ubuntu/data/tensorflow/my_workspace/training_demo/Predictions/snapshot_serengeti_test.csv'\n",
    "\n",
    "\n",
    "dataset = tf.data.Dataset.from_tensor_slices(tfrecord_path_list)\n",
    "dataset = tf.data.TFRecordDataset(dataset)\n",
    "dataset = dataset.repeat(1)\n",
    "dataset = dataset.map(lambda x: decode_record(serialized_example=x)).batch(batch_size)\n",
    "\n",
    "# iterator = dataset.make_one_shot_iterator() # create the iterator\n",
    "# batch_data = iterator.get_next()\n",
    "\n",
    "# Run the session and extract the feature values\n",
    "# with tf.Session() as sess:\n",
    "    \n",
    "xmins_d, ymins_d, xmaxs_d, ymaxs_d, labels_d, scores, filenames = [], [], [], [], [], [], []\n",
    "filenames_without_predictions = []\n",
    "\n",
    "\n",
    "for i, (context, sequence) in enumerate(dataset):\n",
    "    batch_shape = context['image/detection/bbox/xmin'].dense_shape\n",
    "    #context['image/detection/bbox/xmin'][2]\n",
    "\n",
    "    img = context['image/encoded']\n",
    "    filename = context['image/filename']\n",
    "    # Features added during the detection phase \n",
    "    xmin_d = tf.sparse_tensor_to_dense(context['image/detection/bbox/xmin'])\n",
    "    ymin_d = tf.sparse_tensor_to_dense(context['image/detection/bbox/ymin'])\n",
    "    xmax_d = tf.sparse_tensor_to_dense(context['image/detection/bbox/xmax'])\n",
    "    ymax_d = tf.sparse_tensor_to_dense(context['image/detection/bbox/ymax'])\n",
    "    label_d = tf.sparse_tensor_to_dense(context['image/detection/label'])\n",
    "    score = tf.sparse_tensor_to_dense(context['image/detection/score'])\n",
    "\n",
    "\n",
    "    for rec_i in range(0, int(batch_shape[0])):\n",
    "        box_counter = 0\n",
    "        for box_i in range(0, int(batch_shape[1])):\n",
    "            if score[rec_i, box_i] < score_threshold:\n",
    "                continue\n",
    "            xmins_d.append(xmin_d[rec_i, box_i].numpy())\n",
    "            ymins_d.append(xmax_d[rec_i, box_i].numpy())\n",
    "            xmaxs_d.append(ymax_d[rec_i, box_i].numpy())\n",
    "            ymaxs_d.append(ymax_d[rec_i, box_i].numpy())\n",
    "            labels_d.append(label_d[rec_i, box_i].numpy())\n",
    "            scores.append(score[rec_i, box_i].numpy())\n",
    "            filenames.append(filename[rec_i].numpy().decode('utf-8'))\n",
    "\n",
    "            box_counter += 1\n",
    "\n",
    "        if box_counter == 0:\n",
    "            filenames_without_predictions.append(filename[rec_i].numpy().decode('utf-8'))\n",
    "    \n",
    "    print('image: {0} finished'.format(i))\n",
    "\n",
    "            \n",
    " # Create pandas dataframe\n",
    "df_predictions = pd.DataFrame({'labels':labels_d, \n",
    "                               'filename':filenames,\n",
    "                               'score': scores,\n",
    "                               'xmin': xmins_d,\n",
    "                               'ymin': ymins_d,\n",
    "                               'xmax': xmaxs_d,\n",
    "                               'ymax': ymaxs_d})\n",
    "\n",
    "df_predictions = df_predictions.append(pd.DataFrame({'filename':filenames_without_predictions}))\n",
    "# write predictions to csv\n",
    "df_predictions.to_csv(output_csv, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'S1/E02/E02_R5/S1_E02_R5_PICT0056'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filename[rec_i].numpy().decode('utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"tf.Tensor(b'S1/B04/B04_R1/S1_B04_R1_PICT0009', shape=(), dtype=string)\""
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str(filename[rec_i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting /home/ubuntu/data/tensorflow/my_workspace/camera-trap-detection/data_prep/predictor_extractor.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile /home/ubuntu/data/tensorflow/my_workspace/camera-trap-detection/data_prep/predictor_extractor.py\n",
    "\"\"\"Predictor Extractor reads the TFRecords with predictions and outputs the csv file with the predictions \"\"\"\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "\n",
    "tf.enable_eager_execution()\n",
    "\n",
    "def decode_record(serialized_example):\n",
    "    \"\"\"This section contains the helper functions needed for \n",
    "    decoding TFRecord...\n",
    "    1. decode_record: This function decodes a TFexample with the following features\n",
    "                   'image/filename' - a fixed length feature with the file name\n",
    "                   'image/encoded' - a fixed length feature with image encodings\n",
    "                   'image/format' - a fixed length features with image format\n",
    "                   'image/detection/bbox/xmin' - a varaible name feature with normalized xmin values \n",
    "                   'image/detection/bbox/xmax' - normalized xmax values\n",
    "                   'image/detection/bbox/ymin' - normalized ymin values\n",
    "                   'image/detection/bbox/ymax' - normalized ymax values\n",
    "                   'image/detection/label' - bounding box labels\n",
    "                   'image/detection/score' - prediction score\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    context_features = {\n",
    "                        'image/filename': tf.FixedLenFeature([], tf.string),\n",
    "                        'image/encoded': tf.FixedLenFeature([], tf.string),\n",
    "                        'image/format': tf.FixedLenFeature([], tf.string),\n",
    "                        \"image/detection/bbox/xmin\" : tf.VarLenFeature(tf.float32),\n",
    "                        \"image/detection/bbox/xmax\" : tf.VarLenFeature(tf.float32),\n",
    "                        \"image/detection/bbox/ymin\" : tf.VarLenFeature(tf.float32),\n",
    "                        \"image/detection/bbox/ymax\" : tf.VarLenFeature(tf.float32),\n",
    "                        \"image/detection/label\" : tf.VarLenFeature(tf.int64),\n",
    "                        \"image/detection/score\" : tf.VarLenFeature(tf.float32)\n",
    "                    }\n",
    "\n",
    "\n",
    "    context, sequence = tf.parse_single_sequence_example(serialized=serialized_example,\n",
    "                                              context_features=context_features,\n",
    "#                                               sequence_features=sequence_features,\n",
    "                                              example_name=None,\n",
    "                                              name=None)\n",
    "\n",
    "    return ({k: v for k, v in context.items()},{k: v for k, v in sequence.items()})\n",
    "\n",
    "\n",
    "def predictorExtractor(tfrecord_path_list,\n",
    "                       output_csv,\n",
    "                       batch_size=512, \n",
    "                       score_threshold=0.5):\n",
    "    dataset = tf.data.Dataset.from_tensor_slices(tfrecord_path_list)\n",
    "    dataset = tf.data.TFRecordDataset(dataset)\n",
    "    dataset = dataset.repeat(1)\n",
    "    dataset = dataset.map(lambda x: decode_record(serialized_example=x)).batch(batch_size)\n",
    "\n",
    "    xmins_d, ymins_d, xmaxs_d, ymaxs_d, labels_d, scores, filenames = [], [], [], [], [], [], []\n",
    "    filenames_without_predictions = []\n",
    "\n",
    "\n",
    "    for i, (context, sequence) in enumerate(dataset):\n",
    "        batch_shape = context['image/detection/bbox/xmin'].dense_shape\n",
    "        #context['image/detection/bbox/xmin'][2]\n",
    "\n",
    "        img = context['image/encoded']\n",
    "        filename = context['image/filename']\n",
    "        # Features added during the detection phase \n",
    "        xmin_d = tf.sparse_tensor_to_dense(context['image/detection/bbox/xmin'])\n",
    "        ymin_d = tf.sparse_tensor_to_dense(context['image/detection/bbox/ymin'])\n",
    "        xmax_d = tf.sparse_tensor_to_dense(context['image/detection/bbox/xmax'])\n",
    "        ymax_d = tf.sparse_tensor_to_dense(context['image/detection/bbox/ymax'])\n",
    "        label_d = tf.sparse_tensor_to_dense(context['image/detection/label'])\n",
    "        score = tf.sparse_tensor_to_dense(context['image/detection/score'])\n",
    "\n",
    "\n",
    "        for rec_i in range(0, int(batch_shape[0])):\n",
    "            box_counter = 0\n",
    "            for box_i in range(0, int(batch_shape[1])):\n",
    "                if score[rec_i, box_i] < score_threshold:\n",
    "                    continue\n",
    "                xmins_d.append(xmin_d[rec_i, box_i].numpy())\n",
    "                ymins_d.append(ymin_d[rec_i, box_i].numpy())\n",
    "                xmaxs_d.append(xmax_d[rec_i, box_i].numpy())\n",
    "                ymaxs_d.append(ymax_d[rec_i, box_i].numpy())\n",
    "                labels_d.append(int(label_d[rec_i, box_i].numpy()))\n",
    "                scores.append(score[rec_i, box_i].numpy())\n",
    "                filenames.append(filename[rec_i].numpy().decode('utf-8'))\n",
    "\n",
    "                box_counter += 1\n",
    "\n",
    "            if box_counter == 0:\n",
    "                filenames_without_predictions.append(filename[rec_i].numpy().decode('utf-8'))\n",
    "\n",
    "        print('Batch: {0} finished'.format(i))\n",
    "    \n",
    "     # Create pandas dataframe\n",
    "    df_predictions = pd.DataFrame({'labels':labels_d, \n",
    "                                   'filename':filenames,\n",
    "                                   'score': scores,\n",
    "                                   'xmin': xmins_d,\n",
    "                                   'ymin': ymins_d,\n",
    "                                   'xmax': xmaxs_d,\n",
    "                                   'ymax': ymaxs_d})\n",
    "\n",
    "    df_predictions = df_predictions.append(pd.DataFrame({'filename':filenames_without_predictions}))\n",
    "    df_predictions = df_predictions.round({'score':2})\n",
    "    # write predictions to csv\n",
    "    df_predictions.to_csv(output_csv, index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/ubuntu/data/tensorflow/my_workspace/camera-trap-detection/data_prep'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**main file**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting /home/ubuntu/data/tensorflow/my_workspace/camera-trap-detection/predictorExtractor_main.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile /home/ubuntu/data/tensorflow/my_workspace/camera-trap-detection/predictorExtractor_main.py\n",
    "\"\"\"Main function for extracting TFRecord to a csv. \n",
    "Uses the helper modules predictor_extractor.py\"\"\"\n",
    "\n",
    "import argparse\n",
    "\n",
    "from data_prep.predictor_extractor import predictorExtractor\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument(\n",
    "        \"--tfrecord_path_list\", nargs='+', type=str, required=True,\n",
    "        help=\"Path to TFRecord files\")\n",
    "    parser.add_argument(\n",
    "        \"--output_csv\", type=str, required=True,\n",
    "        help=\"output csv file\"\n",
    "        )\n",
    "    parser.add_argument(\n",
    "        \"--batch_size\", type=int, default=512,\n",
    "        help=\"batch size\")\n",
    "    parser.add_argument(\n",
    "        \"--score_threshold\", type=float, default=0.5,\n",
    "        help=\"score thresholds to write to csv\")\n",
    "\n",
    "\n",
    "\n",
    "    kwargs = vars(parser.parse_args())\n",
    "\n",
    "    predictorExtractor(**kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/data/tensorflow/my_workspace/camera-trap-detection\n"
     ]
    }
   ],
   "source": [
    "%cd /home/ubuntu/data/tensorflow/my_workspace/camera-trap-detection/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-42-2e520146664f>, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-42-2e520146664f>\"\u001b[0;36m, line \u001b[0;32m2\u001b[0m\n\u001b[0;31m    --output_csv '/home/ubuntu/data/tensorflow/my_workspace/training_demo/Predictions/snapshot_serengeti_test2.csv'\u001b[0m\n\u001b[0m                                                                                                                  ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "!python predictorExtractor_main \\\n",
    "--tfrecord_path_list '/home/ubuntu/data/tensorflow/my_workspace/training_demo/Predictions/snapshot_serengeti_s01_s06-0-10000.record' \\ \n",
    "--output_csv '/home/ubuntu/data/tensorflow/my_workspace/training_demo/Predictions/snapshot_serengeti_test2.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/ubuntu/data/tensorflow/my_workspace/training_demo/Predictions/snapshot_serengeti_test.csv'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
