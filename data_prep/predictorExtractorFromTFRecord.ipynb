{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to process the TFRecord and create a csv with the fields - filename, class, xmin, ymin, xmax, ymax, prediction_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import modules\n",
    "import csv, os, sys, io\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "sys.path.append('/home/ubuntu/data/tensorflow/my_workspace/camera-trap-detection/data/')\n",
    "from utils import dataset_util\n",
    "from PIL import ImageFile\n",
    "from PIL import Image\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input parameters\n",
    "filename_list = ['/home/ubuntu/data/tensorflow/my_workspace/training_demo/Predictions/snapshot_serengeti_s01_s06-0-10000.record']\n",
    "batch_size = 2\n",
    "score_threshold = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = 0\n",
    "tfrecords_filename = '/home/ubuntu/data/tensorflow/my_workspace/training_demo/Predictions/snapshot_serengeti_s01_s06-0-10000.record'\n",
    "record_iterator = tf.python_io.tf_record_iterator(path=tfrecords_filename)\n",
    "\n",
    "for s_example in record_iterator:\n",
    "    example = tf.train.Example()\n",
    "    example.ParseFromString(s_example)\n",
    "    print(example)\n",
    "    \n",
    "#     box_labels = (example.features.feature[\"image/object/class/label\"]\n",
    "#                                 .int64_list)\n",
    "#     box_class = (example.features.feature[\"image/object/class/text\"]\n",
    "#                                 .bytes_list)\n",
    "#     example = tf.train.Example.FromString(s_example)\n",
    "    c +=1\n",
    "    if c == 1:\n",
    "#         print(box_labels, box_class)\n",
    "        print(box_class)\n",
    "    else :\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"This section contains the helper functions needed for \n",
    "decoding TFRecord...\n",
    "1. decode_record: This function decodes a TFexample with the following features\n",
    "               'image/filename' - a fixed length feature with the file name\n",
    "               'image/encoded' - a fixed length feature with image encodings\n",
    "               'image/format' - a fixed length features with image format\n",
    "               'image/detection/bbox/xmin' - a varaible name feature with normalized xmin values \n",
    "               'image/detection/bbox/xmax' - normalized xmax values\n",
    "               'image/detection/bbox/ymin' - normalized ymin values\n",
    "               'image/detection/bbox/ymax' - normalized ymax values\n",
    "               'image/detection/label' - bounding box labels\n",
    "               'image/detection/score' - prediction score\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "def decode_record(serialized_example):\n",
    "    context_features = {\n",
    "                        'image/filename': tf.FixedLenFeature([], tf.string),\n",
    "                        'image/encoded': tf.FixedLenFeature([], tf.string),\n",
    "                        'image/format': tf.FixedLenFeature([], tf.string),\n",
    "                        \"image/detection/bbox/xmin\" : tf.VarLenFeature(tf.float32),\n",
    "                        \"image/detection/bbox/xmax\" : tf.VarLenFeature(tf.float32),\n",
    "                        \"image/detection/bbox/ymin\" : tf.VarLenFeature(tf.float32),\n",
    "                        \"image/detection/bbox/ymax\" : tf.VarLenFeature(tf.float32),\n",
    "                        \"image/detection/label\" : tf.VarLenFeature(tf.int64),\n",
    "                        \"image/detection/score\" : tf.VarLenFeature(tf.float32)\n",
    "                    }\n",
    "\n",
    "\n",
    "    context, sequence = tf.parse_single_sequence_example(serialized=serialized_example,\n",
    "                                              context_features=context_features,\n",
    "#                                               sequence_features=sequence_features,\n",
    "                                              example_name=None,\n",
    "                                              name=None)\n",
    "\n",
    "    return ({k: v for k, v in context.items()},{k: v for k, v in sequence.items()})\n",
    "\n",
    "# Create an iterator to traverse the file\n",
    "dataset = tf.data.Dataset.from_tensor_slices(filename_list)\n",
    "dataset = tf.data.TFRecordDataset(dataset)\n",
    "dataset = dataset.map(lambda x: decode_record(serialized_example=x)).batch(batch_size)\n",
    "\n",
    "iterator = dataset.make_one_shot_iterator() # create the iterator\n",
    "batch_data = iterator.get_next()\n",
    "\n",
    "# Run the session and extract the feature values\n",
    "with tf.Session() as sess:\n",
    "    (context, sequence) = sess.run(batch_data)\n",
    "    img = context['image/encoded']\n",
    "    filename = context['image/filename']\n",
    "    # Features added during the detection phase \n",
    "    xmin_d = (context['image/detection/bbox/xmin'])\n",
    "    ymin_d = (context['image/detection/bbox/ymin'])\n",
    "    xmax_d = (context['image/detection/bbox/xmax'])\n",
    "    ymax_d = (context['image/detection/bbox/ymax'])\n",
    "    label_d = (context['image/detection/label'])\n",
    "    score = (context['image/detection/score'])\n",
    "    \n",
    "    file_name = [] # list of mages with no groundtruth\n",
    "    no_prediction = [] # Storing the image name of the correct predictions\n",
    "    incorrect_prediction = [] # Storing the image name of the incorrect predictions\n",
    "    \n",
    "    # index of the boxes with score greater than the threshold\n",
    "    index_score_gt_threshold = score[1] > score_threshold # can be checked only once. So moved out of the for loop\n",
    "    xmins_d, ymins_d, xmaxs_d, ymaxs_d, labels_d, scores = [], [], [], [], [], []\n",
    "    for rec_i in range(len(img)):\n",
    "        encoded_jpg_io = io.BytesIO(img[rec_i])\n",
    "        image = Image.open(encoded_jpg_io)\n",
    "        width, height = image.size\n",
    "        \n",
    "        # index of the image\n",
    "        index_image_rec_i = xmin_d[0][:, 0] == rec_i\n",
    "        # index of the boxes with score greater than the threshold\n",
    "        # index_score_gt_threshold = score[1] > score_threshold\n",
    "        index_img_gt_thres = list(np.where([a and b for a, b in zip(index_image_rec_i, index_score_gt_threshold)])[0])\n",
    "        \n",
    "        xmins_d = xmins_d + list(xmin_d[1][index_img_gt_thres])\n",
    "        ymins_d = ymins_d + list(ymin_d[1][index_img_gt_thres])\n",
    "        xmaxs_d = xmaxs_d + list(xmax_d[1][index_img_gt_thres])\n",
    "        ymaxs_d = ymaxs_d + list(ymax_d[1][index_img_gt_thres])\n",
    "        labels_d = labels_d + list(label_d[1][index_img_gt_thres])\n",
    "        scores = scores + list(score[1][index_img_gt_thres])\n",
    "        file_name = file_name + [filename[rec_i].decode('ascii')]*len(index_img_gt_thres)\n",
    "        \n",
    "        if len(index_img_gt_thres)==0:\n",
    "            no_prediction.append(filename[rec_i].decode('ascii'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/test_env/lib/python3.5/site-packages/pandas/core/frame.py:6211: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  sort=sort)\n"
     ]
    }
   ],
   "source": [
    "# Create pandas dataframe\n",
    "df_predictions = pd.DataFrame({'labels':labels_d, \n",
    "                               'filename':file_name,\n",
    "                               'score': scores,\n",
    "                               'xmin': xmins_d,\n",
    "                               'ymin': ymins_d,\n",
    "                               'xmax': xmaxs_d,\n",
    "                               'ymax': ymaxs_d})\n",
    "df_predictions = df_predictions.append(pd.DataFrame({'filename':no_prediction}))\n",
    "# write predictions to csv\n",
    "# df_predictions.to_csv('/home/ubuntu/data/tensorflow/my_workspace/training_demo/Predictions/snapshot_serengeti_s01_s06-0-10000.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# context['image/detection/bbox/ymin'][0].shape\n",
    "xmin_test = tf.sparse_tensor_to_dense(\n",
    "    context['image/detection/bbox/xmin'],\n",
    "    default_value=0,\n",
    "    validate_indices=True,\n",
    "    name=None\n",
    ")\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    print(sess.run(xmin_test))\n",
    "    print(sess.run(xmin_test[0,5]))\n",
    "# context['image/detection/bbox/xmin']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image: 0 finished\n",
      "image: 1 finished\n",
      "image: 2 finished\n",
      "image: 3 finished\n",
      "image: 4 finished\n",
      "image: 5 finished\n",
      "image: 6 finished\n",
      "image: 7 finished\n",
      "image: 8 finished\n",
      "image: 9 finished\n",
      "image: 10 finished\n",
      "image: 11 finished\n",
      "image: 12 finished\n",
      "image: 13 finished\n",
      "image: 14 finished\n",
      "image: 15 finished\n",
      "image: 16 finished\n",
      "image: 17 finished\n",
      "image: 18 finished\n",
      "image: 19 finished\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/test_env/lib/python3.5/site-packages/pandas/core/frame.py:6211: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  sort=sort)\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Predictor Extractor reads the TFRecords with predictions and outputs the csv file with the predictions \"\"\"\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "\n",
    "# tf.enable_eager_execution()\n",
    "\n",
    "def decode_record(serialized_example):\n",
    "    \"\"\"This section contains the helper functions needed for \n",
    "    decoding TFRecord...\n",
    "    1. decode_record: This function decodes a TFexample with the following features\n",
    "                   'image/filename' - a fixed length feature with the file name\n",
    "                   'image/encoded' - a fixed length feature with image encodings\n",
    "                   'image/format' - a fixed length features with image format\n",
    "                   'image/detection/bbox/xmin' - a varaible name feature with normalized xmin values \n",
    "                   'image/detection/bbox/xmax' - normalized xmax values\n",
    "                   'image/detection/bbox/ymin' - normalized ymin values\n",
    "                   'image/detection/bbox/ymax' - normalized ymax values\n",
    "                   'image/detection/label' - bounding box labels\n",
    "                   'image/detection/score' - prediction score\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    context_features = {\n",
    "                        'image/filename': tf.FixedLenFeature([], tf.string),\n",
    "                        'image/encoded': tf.FixedLenFeature([], tf.string),\n",
    "                        'image/format': tf.FixedLenFeature([], tf.string),\n",
    "                        \"image/detection/bbox/xmin\" : tf.VarLenFeature(tf.float32),\n",
    "                        \"image/detection/bbox/xmax\" : tf.VarLenFeature(tf.float32),\n",
    "                        \"image/detection/bbox/ymin\" : tf.VarLenFeature(tf.float32),\n",
    "                        \"image/detection/bbox/ymax\" : tf.VarLenFeature(tf.float32),\n",
    "                        \"image/detection/label\" : tf.VarLenFeature(tf.int64),\n",
    "                        \"image/detection/score\" : tf.VarLenFeature(tf.float32)\n",
    "                    }\n",
    "\n",
    "\n",
    "    context, sequence = tf.parse_single_sequence_example(serialized=serialized_example,\n",
    "                                              context_features=context_features,\n",
    "#                                               sequence_features=sequence_features,\n",
    "                                              example_name=None,\n",
    "                                              name=None)\n",
    "\n",
    "    return ({k: v for k, v in context.items()},{k: v for k, v in sequence.items()})\n",
    "\n",
    "\n",
    "tfrecord_path_list = ['/home/ubuntu/data/tensorflow/my_workspace/training_demo/Predictions/snapshot_serengeti_s01_s06-0-10000.record']\n",
    "batch_size = 512\n",
    "score_threshold = 0.5\n",
    "output_csv = '/home/ubuntu/data/tensorflow/my_workspace/training_demo/Predictions/snapshot_serengeti_test.csv'\n",
    "\n",
    "\n",
    "dataset = tf.data.Dataset.from_tensor_slices(tfrecord_path_list)\n",
    "dataset = tf.data.TFRecordDataset(dataset)\n",
    "dataset = dataset.repeat(1)\n",
    "dataset = dataset.map(lambda x: decode_record(serialized_example=x)).batch(batch_size)\n",
    "\n",
    "# iterator = dataset.make_one_shot_iterator() # create the iterator\n",
    "# batch_data = iterator.get_next()\n",
    "\n",
    "# Run the session and extract the feature values\n",
    "# with tf.Session() as sess:\n",
    "    \n",
    "xmins_d, ymins_d, xmaxs_d, ymaxs_d, labels_d, scores, filenames = [], [], [], [], [], [], []\n",
    "filenames_without_predictions = []\n",
    "\n",
    "\n",
    "for i, (context, sequence) in enumerate(dataset):\n",
    "    batch_shape = context['image/detection/bbox/xmin'].dense_shape\n",
    "    #context['image/detection/bbox/xmin'][2]\n",
    "\n",
    "    img = context['image/encoded']\n",
    "    filename = context['image/filename']\n",
    "    # Features added during the detection phase \n",
    "    xmin_d = tf.sparse_tensor_to_dense(context['image/detection/bbox/xmin'])\n",
    "    ymin_d = tf.sparse_tensor_to_dense(context['image/detection/bbox/ymin'])\n",
    "    xmax_d = tf.sparse_tensor_to_dense(context['image/detection/bbox/xmax'])\n",
    "    ymax_d = tf.sparse_tensor_to_dense(context['image/detection/bbox/ymax'])\n",
    "    label_d = tf.sparse_tensor_to_dense(context['image/detection/label'])\n",
    "    score = tf.sparse_tensor_to_dense(context['image/detection/score'])\n",
    "\n",
    "\n",
    "    for rec_i in range(0, int(batch_shape[0])):\n",
    "        box_counter = 0\n",
    "        for box_i in range(0, int(batch_shape[1])):\n",
    "            if score[rec_i, box_i] < score_threshold:\n",
    "                continue\n",
    "            xmins_d.append(xmin_d[rec_i, box_i].numpy())\n",
    "            ymins_d.append(xmax_d[rec_i, box_i].numpy())\n",
    "            xmaxs_d.append(ymax_d[rec_i, box_i].numpy())\n",
    "            ymaxs_d.append(ymax_d[rec_i, box_i].numpy())\n",
    "            labels_d.append(label_d[rec_i, box_i].numpy())\n",
    "            scores.append(score[rec_i, box_i].numpy())\n",
    "            filenames.append(filename[rec_i].numpy().decode('utf-8'))\n",
    "\n",
    "            box_counter += 1\n",
    "\n",
    "        if box_counter == 0:\n",
    "            filenames_without_predictions.append(filename[rec_i].numpy().decode('utf-8'))\n",
    "    \n",
    "    print('image: {0} finished'.format(i))\n",
    "\n",
    "            \n",
    " # Create pandas dataframe\n",
    "df_predictions = pd.DataFrame({'labels':labels_d, \n",
    "                               'filename':filenames,\n",
    "                               'score': scores,\n",
    "                               'xmin': xmins_d,\n",
    "                               'ymin': ymins_d,\n",
    "                               'xmax': xmaxs_d,\n",
    "                               'ymax': ymaxs_d})\n",
    "\n",
    "df_predictions = df_predictions.append(pd.DataFrame({'filename':filenames_without_predictions}))\n",
    "# write predictions to csv\n",
    "df_predictions.to_csv(output_csv, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting /home/ubuntu/data/tensorflow/my_workspace/camera-trap-detection/data_prep/predictor_extractor.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile /home/ubuntu/data/tensorflow/my_workspace/camera-trap-detection/data_prep/predictor_extractor.py\n",
    "\"\"\"Predictor Extractor reads the TFRecords with predictions and outputs the csv file with the predictions \"\"\"\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "\n",
    "tf.enable_eager_execution()\n",
    "\n",
    "def decode_record(serialized_example, discard_image_pixels=True):\n",
    "    \"\"\"This section contains the helper functions needed for \n",
    "    decoding TFRecord...\n",
    "    1. decode_record: This function decodes a TFexample with the following features\n",
    "                   'image/filename' - a fixed length feature with the file name\n",
    "                   'image/encoded' - a fixed length feature with image encodings\n",
    "                   'image/format' - a fixed length features with image format\n",
    "                   'image/detection/bbox/xmin' - a varaible name feature with normalized xmin values \n",
    "                   'image/detection/bbox/xmax' - normalized xmax values\n",
    "                   'image/detection/bbox/ymin' - normalized ymin values\n",
    "                   'image/detection/bbox/ymax' - normalized ymax values\n",
    "                   'image/detection/label' - bounding box labels\n",
    "                   'image/detection/score' - prediction score\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    context_features = {\n",
    "                        'image/filename': tf.FixedLenFeature([], tf.string),\n",
    "                        # 'image/encoded': tf.FixedLenFeature([], tf.string),\n",
    "                        'image/format': tf.FixedLenFeature([], tf.string),\n",
    "                        \"image/detection/bbox/xmin\" : tf.VarLenFeature(tf.float32),\n",
    "                        \"image/detection/bbox/xmax\" : tf.VarLenFeature(tf.float32),\n",
    "                        \"image/detection/bbox/ymin\" : tf.VarLenFeature(tf.float32),\n",
    "                        \"image/detection/bbox/ymax\" : tf.VarLenFeature(tf.float32),\n",
    "                        \"image/detection/label\" : tf.VarLenFeature(tf.int64),\n",
    "                        \"image/detection/score\" : tf.VarLenFeature(tf.float32)\n",
    "                    }\n",
    "\n",
    "\n",
    "    context, sequence = tf.parse_single_sequence_example(serialized=serialized_example,\n",
    "                                              context_features=context_features,\n",
    "#                                               sequence_features=sequence_features,\n",
    "                                              example_name=None,\n",
    "                                              name=None)\n",
    "\n",
    "    return ({k: v for k, v in context.items()},{k: v for k, v in sequence.items()})\n",
    "\n",
    "\n",
    "def predictorExtractor(tfrecord_path_list,\n",
    "                       output_csv,\n",
    "                       groundtruth_consolidated_dict,\n",
    "                       discard_image_pixels=True,\n",
    "                       batch_size=512, \n",
    "                       score_threshold=0.5,\n",
    "                       score_threshold_lower_bound_for_bootstrap=0.5,\n",
    "                       is_training='True'):\n",
    "    \"\"\"\n",
    "    This requires a dicrionary with groudtruth file name and total animals in it\n",
    "    \"\"\"\n",
    "    \n",
    "    dataset = tf.data.Dataset.from_tensor_slices(tfrecord_path_list)\n",
    "    dataset = tf.data.TFRecordDataset(dataset)\n",
    "    dataset = dataset.repeat(1)\n",
    "    dataset = dataset.map(lambda x: decode_record(serialized_example=x)).batch(batch_size)\n",
    "\n",
    "    xmins_d, ymins_d, xmaxs_d, ymaxs_d, labels_d, scores, filenames = [], [], [], [], [], [], []\n",
    "    filenames_without_predictions = []\n",
    "\n",
    "\n",
    "    for i, (context, sequence) in enumerate(dataset):\n",
    "        batch_shape = context['image/detection/bbox/xmin'].dense_shape\n",
    "        #context['image/detection/bbox/xmin'][2]\n",
    "        # if discard_image_pixels!=True:\n",
    "        # img = context['image/encoded']\n",
    "        filename = context['image/filename']\n",
    "        # Features added during the detection phase \n",
    "        xmin_d = tf.sparse_tensor_to_dense(context['image/detection/bbox/xmin'])\n",
    "        ymin_d = tf.sparse_tensor_to_dense(context['image/detection/bbox/ymin'])\n",
    "        xmax_d = tf.sparse_tensor_to_dense(context['image/detection/bbox/xmax'])\n",
    "        ymax_d = tf.sparse_tensor_to_dense(context['image/detection/bbox/ymax'])\n",
    "        label_d = tf.sparse_tensor_to_dense(context['image/detection/label'])\n",
    "        score = tf.sparse_tensor_to_dense(context['image/detection/score'])\n",
    "\n",
    "\n",
    "        for rec_i in range(0, int(batch_shape[0])):\n",
    "            if is_training=='True':\n",
    "                num_box = groundtruth_consolidated_dict[filename[rec_i].numpy().decode('utf-8')]\n",
    "                if num_box in ['11-50', '51+']:\n",
    "                    score_threshold = 0.25\n",
    "                else:\n",
    "                    # max(min(scores), lower_bound) to enforce quality of boxes\n",
    "                    score_threshold = max(min(score[rec_i, 0:int(num_box)]), score_threshold_lower_bound_for_bootstrap)\n",
    "            box_counter = 0\n",
    "            for box_i in range(0, int(batch_shape[1])):\n",
    "                if score[rec_i, box_i] < score_threshold:\n",
    "                    continue\n",
    "                xmins_d.append(xmin_d[rec_i, box_i].numpy())\n",
    "                ymins_d.append(ymin_d[rec_i, box_i].numpy())\n",
    "                xmaxs_d.append(xmax_d[rec_i, box_i].numpy())\n",
    "                ymaxs_d.append(ymax_d[rec_i, box_i].numpy())\n",
    "                labels_d.append(int(label_d[rec_i, box_i].numpy()))\n",
    "                scores.append(score[rec_i, box_i].numpy())\n",
    "                filenames.append(filename[rec_i].numpy().decode('utf-8'))\n",
    "\n",
    "                box_counter += 1\n",
    "\n",
    "            if box_counter == 0:\n",
    "                filenames_without_predictions.append(filename[rec_i].numpy().decode('utf-8'))\n",
    "\n",
    "        print('Batch: {0} finished'.format(i))\n",
    "    \n",
    "     # Create pandas dataframe\n",
    "    df_predictions = pd.DataFrame({'labels':labels_d, \n",
    "                                   'filename':filenames,\n",
    "                                   'score': scores,\n",
    "                                   'xmin': xmins_d,\n",
    "                                   'ymin': ymins_d,\n",
    "                                   'xmax': xmaxs_d,\n",
    "                                   'ymax': ymaxs_d})\n",
    "\n",
    "    df_predictions = df_predictions.append(pd.DataFrame({'filename':filenames_without_predictions}))\n",
    "    df_predictions = df_predictions.round({'score':2})\n",
    "    # write predictions to csv\n",
    "    df_predictions.to_csv(output_csv, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**main file**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting /home/ubuntu/data/tensorflow/my_workspace/camera-trap-detection/predictorExtractor_main.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile /home/ubuntu/data/tensorflow/my_workspace/camera-trap-detection/predictorExtractor_main.py\n",
    "\"\"\"Main function for extracting TFRecord to a csv. \n",
    "Uses the helper modules predictor_extractor.py\"\"\"\n",
    "\n",
    "import argparse\n",
    "import pandas as pd\n",
    "\n",
    "from data_prep.predictor_extractor import predictorExtractor\n",
    "import data_prep.data_prep_utils as dataprep_utils\n",
    "import bootstrapping.prediction_groundtruth_consolidation as pgc\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument(\n",
    "        \"--tfrecord_path_list\", nargs='+', type=str, required=True,\n",
    "        help=\"Path to TFRecord files\")\n",
    "    parser.add_argument(\n",
    "        \"--output_csv\", type=str, required=True,\n",
    "        help=\"output csv file\"\n",
    "        )\n",
    "    parser.add_argument(\n",
    "        \"--batch_size\", type=int, default=512,\n",
    "        help=\"batch size\")\n",
    "    parser.add_argument(\n",
    "        \"--score_threshold\", type=float, default=0.5,\n",
    "        help=\"score thresholds to write to csv\")\n",
    "    parser.add_argument(\n",
    "        \"--discard_image_pixels\", type=bool, default=True,\n",
    "        help=\"True to discard the pixel encodings or when pixel encodings are not present in the datafile\")\n",
    "    parser.add_argument(\n",
    "        \"--groundtruth_csv_path\", type=str, required=True,\n",
    "        help=\"path to the groundtruth file\"\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--label_map_json\", type=str, required=True,\n",
    "        help=\"path to the label map json file\")\n",
    "    parser.add_argument(\n",
    "        \"--is_training\", type=str, default='True',\n",
    "        help=\"if the data is for the training purposes of bootstrapping step. 1 for training 0 for test\")\n",
    "    parser.add_argument(\n",
    "        \"--score_threshold_lower_bound_for_bootstrap\", type=float, default=0.0,\n",
    "        help=\"lower bound for score thresholds for bootstrapping rounds\")\n",
    "\n",
    "\n",
    "#     kwargs = vars(parser.parse_args())\n",
    "    args = parser.parse_args()\n",
    "    \n",
    "    label_map_df = pd.DataFrame.from_dict(dataprep_utils.get_label_map_from_json(args.label_map_json), orient='index').reset_index()\n",
    "    label_map_df.columns=['species', 'labels']\n",
    "\n",
    "    groundtruth_df_img = pgc.process_grondtruth_classification_data(args.groundtruth_csv_path, label_map_df)\n",
    "    groundtruth_dict = groundtruth_df_img.to_dict(orient='index')\n",
    "    groundtruth_consolidated_dict = {}\n",
    "    \n",
    "    for k, v in groundtruth_dict.items():\n",
    "        if v['filename'] not in groundtruth_consolidated_dict.keys():\n",
    "            groundtruth_consolidated_dict[v['filename']] = v['groundtruth_counts']\n",
    "        elif v['groundtruth_counts'] == '11-50' and groundtruth_consolidated_dict[v['filename']] != '51+':\n",
    "            groundtruth_consolidated_dict[v['filename']] = '11-50'\n",
    "        elif v['groundtruth_counts'] != '51+' and groundtruth_consolidated_dict[v['filename']] == '11-50':\n",
    "            groundtruth_consolidated_dict[v['filename']] = '11-50'\n",
    "        elif v['groundtruth_counts'] == '51+' or groundtruth_consolidated_dict[v['filename']] == '51+':\n",
    "            groundtruth_consolidated_dict[v['filename']] = '51+'\n",
    "        else:\n",
    "            groundtruth_consolidated_dict[v['filename']] = int(groundtruth_consolidated_dict[v['filename']])+int(v['groundtruth_counts'])\n",
    "            \n",
    "    predictorExtractor(args.tfrecord_path_list, args.output_csv, groundtruth_consolidated_dict, is_training=args.is_training)\n",
    "#     predictorExtractor(**kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
